# Multilingual HM-Conformer Evaluation Summary

- Generated: `2025-12-13 05:00:03`
- labels.json: `/content/deepfake-speech-detection/HM-Conformer/dataset/labels.json`
- dataset_root: `/content/deepfake-speech-detection/HM-Conformer/dataset`
- path_params: `/content/deepfake-speech-detection/HM-Conformer/results/Multilingual Training/HM-Conformer_de/models`
- load_epoch: `10`

## Overall Results Summary

| Language | Test Samples | EER (%) | Accuracy | F1 | Precision | Recall | ROC AUC | Exit |
|---|---:|---:|---:|---:|---:|---:|---:|---:|
| **pl** | 16,040 | 6.29 | 0.9386 | 0.9383 | 0.9398 | 0.9369 | 0.9386 | 0 |
| **en** | 89,475 | 6.72 | 0.9709 | 0.9809 | 0.9778 | 0.9841 | 0.9566 | 0 |
| **fr** | 46,895 | 7.61 | 0.9498 | 0.9415 | 0.8921 | 0.9968 | 0.9573 | 0 |
| **it** | 37,624 | 7.66 | 0.9448 | 0.9343 | 0.8888 | 0.9848 | 0.9516 | 0 |
| **es** | 30,498 | 10.34 | 0.9271 | 0.9145 | 0.8491 | 0.9909 | 0.9383 | 0 |
| **de** | 53,468 | 11.57 | 0.9089 | 0.8738 | 0.7809 | 0.9917 | 0.9310 | 0 |
| **uk** | 16,817 | 13.12 | 0.9012 | 0.8777 | 0.7860 | 0.9935 | 0.9217 | 0 |
| **ru** | 13,183 | 32.15 | 0.7744 | 0.8232 | 0.7049 | 0.9893 | 0.7602 | 0 |

## Per-language Logs

Each run produces a full console log (`.txt`) per language in the output folder.

